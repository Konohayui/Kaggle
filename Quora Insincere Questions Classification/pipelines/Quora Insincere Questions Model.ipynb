{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np, pandas as pd, random as rn, os, gc, re\n\nseed = 32\nnp.random.seed(seed)\nrn.seed(seed)\nimport tensorflow as tf\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads = 1,\n                              inter_op_parallelism_threads = 1)\ntf.set_random_seed(seed) \nsess = tf.Session(graph = tf.get_default_graph(), config = session_conf)\nfrom keras import backend as K\nK.set_session(sess)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import f1_score\n\nfrom keras.layers import Input, Dense, CuDNNLSTM, Bidirectional, Activation, Conv1D\nfrom keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D\nfrom keras.layers import Add, Flatten, BatchNormalization, GlobalAveragePooling1D\nfrom keras.layers import concatenate, SpatialDropout1D, CuDNNGRU\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Model, load_model\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\nembedding_file = \"../input/embeddings/glove.840B.300d/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 100000\nmax_len = 60\n\nbatch_size = 1024\nepochs = 10",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e093e66c18920594dc7433d3e6364dd5b211faa"
      },
      "cell_type": "code",
      "source": "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n                       \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \n                       \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n                       \"how'd\": \"how did\", \n                       \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n                       \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n                       \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n                       \"i'd\": \"i would\", \n                       \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\n                       \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n                       \"it'd've\": \"it would have\", \"it'll\": \"it will\", \n                       \"it'll've\": \"it will have\",\n                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \n                       \"mayn't\": \"may not\", \n                       \"might've\": \"might have\",\"mightn't\": \"might not\",\n                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \n                       \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n                       \"needn't\": \"need not\", \n                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n                       \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n                       \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \n                       \"shan't've\": \"shall not have\", \n                       \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n                       \"she'll\": \"she will\", \n                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \n                       \"should've\": \"should have\", \n                       \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \n                       \"so've\": \"so have\", \"so's\": \"so as\", \"this's\": \"this is\",\n                       \"that'd\": \"that would\", \n                       \"that'd've\": \"that would have\", \"that's\": \"that is\", \n                       \"there'd\": \"there would\", \n                       \"there'd've\": \"there would have\", \"there's\": \"there is\", \n                       \"here's\": \"here is\",\n                       \"they'd\": \"they would\", \"they'd've\": \"they would have\", \n                       \"they'll\": \"they will\", \n                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \n                       \"they've\": \"they have\", \n                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n                       \"we'd've\": \"we would have\", \"we'll\": \"we will\", \n                       \"we'll've\": \"we will have\", \n                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n                       \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n                       \"what're\": \"what are\",  \n                       \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n                       \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n                       \"where've\": \"where have\", \"who'll\": \"who will\", \n                       \"who'll've\": \"who will have\", \n                       \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n                       \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n                       \"won't've\": \"will not have\", \"would've\": \"would have\", \n                       \"wouldn't\": \"would not\", \n                       \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \n                       \"y'all'd\": \"you all would\",\n                       \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\",\n                       \"y'all've\": \"you all have\",\"you'd\": \"you would\", \n                       \"you'd've\": \"you would have\", \n                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \n                       \"you've\": \"you have\" }\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', \n                'travelling': 'traveling', \n                'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', \n                'labour': 'labor', \n                'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', \n                'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', \n                'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', \n                'howcan': 'how can', \n                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', \n                'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', \n                'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', \n                'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', \n                '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', \n                'demonitisation': 'demonetization', 'demonitization': 'demonetization', \n                'demonetisation': 'demonetization'}\n\npunct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \n                 \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", \n                 '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', \n                 '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }    \n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', \n          '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n          '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  \n          '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”', \n          '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', \n          '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', \n          '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', \n          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', \n          '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', \n          '¹', '≤', '‡', '√', 'β', 'α', '∅', 'θ', '÷', '₹']\n\ndef clean_punct(x):\n    x = str(x)\n    for punct in puncts:\n        if punct in x:\n            x = x.replace(punct, f' {punct} ')\n    return x\n\ndef clean_text(x):\n    x = x.lower()\n    for dic in [contraction_mapping, mispell_dict, punct_mapping]:\n        for word in dic.keys():\n            x = x.replace(word, dic[word])\n    return x \n\ntrain[\"question_text\"] = train[\"question_text\"].apply(lambda x: clean_punct(x))\ntest[\"question_text\"] = test[\"question_text\"].apply(lambda x: clean_punct(x))\nprint(\"Text cleaning completed!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "44bed33c86a60709dd2ddaca2946386a05ce8562"
      },
      "cell_type": "code",
      "source": "sincere = train[train[\"target\"] == 0]\ninsincere = train[train[\"target\"] == 1]\n\ntrain = pd.concat([sincere[:int(len(sincere)*0.8)], insincere[:int(len(insincere)*0.8)]])\nval = pd.concat([sincere[int(len(sincere)*0.8):], insincere[int(len(insincere)*0.8):]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a711dd552330ba1c413098ea6ed02e75a0aaf77d"
      },
      "cell_type": "code",
      "source": "X_train, y_train = train[\"question_text\"], train[\"target\"].values\nX_val, y_val = val[\"question_text\"], val[\"target\"].values\n\ntokenizer = Tokenizer(num_words = max_features, \n                      filters = '\"#$%&()*+/:;<=>@[\\]^_`{|}~',\n                      lower = True)\ntokenizer.fit_on_texts(X_train)\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_val = tokenizer.texts_to_sequences(X_val)\nX_test = tokenizer.texts_to_sequences(test[\"question_text\"])\n\nX_train = pad_sequences(X_train, maxlen = max_len)\nX_val = pad_sequences(X_val, maxlen = max_len)\nX_test = pad_sequences(X_test, maxlen = max_len)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e73d9bae6a5e105b44ca095bbcfa69c341235590"
      },
      "cell_type": "code",
      "source": "train_idx = np.random.permutation(len(X_train))\nval_idx = np.random.permutation(len(X_val))\n\nX_train = X_train[train_idx]\nX_val = X_val[val_idx]\ny_train = y_train[train_idx]\ny_val = y_val[val_idx]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41e2b059afeaacd095b456aed29b5217050d9481"
      },
      "cell_type": "code",
      "source": "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(embedding_file))\n\nall_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nembed_size = all_embs.shape[1]\n\nword_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n        \nprint(\"There are {} words being used.\".format(nb_words))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64a485d0249205f6f0ed567387fd6fc8db497160"
      },
      "cell_type": "code",
      "source": "from keras.engine import Layer, InputSpec\nfrom keras.layers import K\n\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0815a7a8b0463de729f06e6d9ac4ab91dbcbe27"
      },
      "cell_type": "code",
      "source": "def visual_model(hist = None):\n    plt.figure(figsize = (10, 8))\n    plt.plot(hist.history[\"acc\"])\n    plt.plot(hist.history[\"val_acc\"])\n    plt.title(\"Model Accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"accuracy\")\n    plt.legend([\"train\", \"val\"], loc = \"upper left\")\n    plt.show()\n\n    plt.figure(figsize = (10, 8))\n    plt.plot(hist.history[\"loss\"])\n    plt.plot(hist.history[\"val_loss\"])\n    plt.title(\"Model Loss\")\n    plt.xlabel(\"epochs\")\n    plt.ylabel(\"loss\")\n    plt.legend([\"train\", \"val\"], loc = \"upper left\")\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60b6793c78466193c866f7b549d1159fae9de0e8"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve, precision_recall_curve\n\ndef threshold_search(y_true, y_proba, plot=False):\n    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n    thresholds = np.append(thresholds, 1.001) \n    F = 2 / (1/precision + 1/recall)\n    best_score = np.max(F)\n    best_th = thresholds[np.argmax(F)]\n    if plot:\n        plt.plot(thresholds, F, '-b')\n        plt.plot([best_th], [best_score], '*r')\n        plt.show()\n    return best_th, best_score ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f6f0a3c20792c46526c47231a18ae784c8e25548"
      },
      "cell_type": "markdown",
      "source": "### Simple LSTM Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c2123cea8310d7124a0e8fec1c80e2eef5e576a"
      },
      "cell_type": "code",
      "source": "def build_lstm_model(units, dr):\n    inp = Input(shape = (max_len, ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr)(embed_layer)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    x = Attention(max_len)(x)\n    \n    x = Dense(128)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n#     x = Dense(64)(x)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n    \n    out = Dense(1, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4dafde012cc906e4529d98e4945614c00851d953"
      },
      "cell_type": "code",
      "source": "units, dr = 64, 0.5\nmodel = build_lstm_model(units, dr)\nslstm_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                       validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "448458224f715c04054a9aaaa0c7ec49cf122bc5"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "04def37a75a475a470d39a281a9ecafc1a6df85c"
      },
      "cell_type": "markdown",
      "source": "### Double LSTM Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65b5c982ef1942deeb02cd91774a4549742851db"
      },
      "cell_type": "code",
      "source": "def build_lstm_model(units, dr):\n    inp = Input(shape = (max_len, ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr)(embed_layer)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    x = Attention(max_len)(x)\n    \n    x = Dense(64, activation = \"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n#     x = Dense(64, activation = \"relu\")(x)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n    \n    out = Dense(1, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b8b4cbd19c359edd7685bda92a8a5bb6dc11905"
      },
      "cell_type": "code",
      "source": "units, dr = 64, 0.5\nmodel = build_lstm_model(units, dr)\ndlstm_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                       validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f9c15666d4e063a039ab9cc7d44f02a4bfb3c43",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "abbfbd5f4d046b11cb4b6cc87da420381434304a"
      },
      "cell_type": "markdown",
      "source": "### RNN Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a238a97c8498208377499329cc105dba5b7b92f6"
      },
      "cell_type": "code",
      "source": "def build_rnn_model(units, dr):\n    inp = Input(shape = (max_len, ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr)(embed_layer)\n    x = Bidirectional(CuDNNGRU(units, return_sequences = True))(x)\n    x = Bidirectional(CuDNNGRU(units, return_sequences = True))(x)\n    x = Attention(max_len)(x)\n    \n    x = Dense(64, activation = \"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n#     x = Dense(64, activation = \"relu\")(x)\n#     x = BatchNormalization()(x)\n#     x = Activation(\"relu\")(x)\n    \n    out = Dense(1, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c566681f2fcd8abbd204c7383fe48a7fbcb633e"
      },
      "cell_type": "code",
      "source": "units, dr = 64, 0.5\nmodel = build_rnn_model(units, dr)\nrnn_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                     validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3e936c5efbd78d9726e38e3ce78944db1e26093"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "219728d4936dd975d77b59bdc90cc4fc8a6bf563"
      },
      "cell_type": "markdown",
      "source": "### RCNN Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08b36ae7b97baf03a4d513da2cae2efb1ae47d01"
      },
      "cell_type": "code",
      "source": "def build_rcnn_model(units,filters, dr):\n    inp = Input(shape = (max_len, ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr)(embed_layer)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    x = Conv1D(filters, 2, activation = \"relu\", kernel_initializer = \"glorot_uniform\")(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    main = concatenate([avg_pool, max_pool])\n    \n    out = Dense(1, activation = \"sigmoid\")(main)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3f3506b72a6883d4c266d33288f5a2e6a8fb8cb"
      },
      "cell_type": "code",
      "source": "units, filters, dr = 64, 32, 0.5\nmodel = build_rcnn_model(units, filters, dr)\nrcnn_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                     validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0732e4d153dcb3d8864edd7599470ab2ccdbe7ab"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "10c8a1162107a5d97688650fc9403ecbcf3e6ed4"
      },
      "cell_type": "markdown",
      "source": "### D-LSTM Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "034538cd4816742dd430e8d21bcecb2be59daa3a"
      },
      "cell_type": "code",
      "source": "from keras.layers import RepeatVector, TimeDistributed, concatenate\n\ndef build_rcnn_model(units,filters, dr):\n    inp = Input(shape = (max_len, ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr)(embed_layer)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    x = Bidirectional(CuDNNLSTM(units, return_sequences = True))(x)\n    \n    atten = Attention(max_len)(x)\n    max_pool = GlobalMaxPooling1D()(x)\n    avg_pool = GlobalAveragePooling1D()(x)\n    x = concatenate([atten, max_pool, avg_pool])\n    x = Dense(64, activation = \"relu\")(x)\n    \n    out = Dense(1, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d39872f4657af60d06c702527a2c6be2b1b4c27e"
      },
      "cell_type": "code",
      "source": "units, filters, dr = 64, 32, 0.5\nmodel = build_rcnn_model(units, filters, dr)\ndlstm_pool_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                            validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "174f247bbf425b993f1e416cbcd82c6761812356"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd4f62b6d89087ac95019e454fde26dc25e692b2"
      },
      "cell_type": "markdown",
      "source": "### Capsule Network"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9e6b6d3c22fd50b798d83106a124391fe15cd1e"
      },
      "cell_type": "code",
      "source": "from keras.engine import Layer, InputSpec\nfrom keras.layers import K\n\ndef squash(x, axis=-1):\n    # s_squared_norm is really small\n    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n    # return scale * x\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n    scale = K.sqrt(s_squared_norm + K.epsilon())\n    return x / scale\n\n# A Capsule Implement with Pure Keras\nclass Capsule(Layer):\n    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n                 activation='default', **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_size = kernel_size\n        self.share_weights = share_weights\n        if activation == 'default':\n            self.activation = squash\n        else:\n            self.activation = Activation(activation)\n\n    def build(self, input_shape):\n        super(Capsule, self).build(input_shape)\n        input_dim_capsule = input_shape[-1]\n        if self.share_weights:\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(1, input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     # shape=self.kernel_size,\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n        else:\n            input_num_capsule = input_shape[-2]\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(input_num_capsule,\n                                            input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n\n    def call(self, u_vecs):\n        if self.share_weights:\n            u_hat_vecs = K.conv1d(u_vecs, self.W)\n        else:\n            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n\n        batch_size = K.shape(u_vecs)[0]\n        input_num_capsule = K.shape(u_vecs)[1]\n        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n                                            self.num_capsule, self.dim_capsule))\n        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n\n        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n        for i in range(self.routings):\n            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n            c = K.softmax(b)\n            c = K.permute_dimensions(c, (0, 2, 1))\n            b = K.permute_dimensions(b, (0, 2, 1))\n            outputs = self.activation(tf.keras.backend.batch_dot(c, u_hat_vecs, [2, 2]))\n            if i < self.routings - 1:\n                b = tf.keras.backend.batch_dot(outputs, u_hat_vecs, [2, 3])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (None, self.num_capsule, self.dim_capsule)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3393b6b775529cecda10ca583a107d0a6287c47"
      },
      "cell_type": "code",
      "source": "from keras.initializers import glorot_uniform, orthogonal\n\ndef build_capsule_model(units = 40, dr = 0.3, \n                        num_capsules = 10, dim_capsules = 10, routs = 4):\n    inp = Input(shape = (max_len, ))\n#     num_input = Input(shape = (num_feat.shape[1], ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr, seed = seed)(embed_layer)\n    x = Bidirectional(CuDNNLSTM(units, kernel_initializer = glorot_uniform(seed = seed), \n                                recurrent_initializer = orthogonal(gain = 1.0, seed = seed), \n                                return_sequences = True))(x)\n\n    x = Capsule(num_capsule = num_capsules, dim_capsule = dim_capsules, routings = routs, share_weights = True)(x)\n    x = Flatten()(x)\n    \n#     x = concatenate([x, num_input])\n    main = Dense(128, kernel_initializer = glorot_uniform(seed = seed))(x)\n#     main = BatchNormalization()(main)\n    main = Activation(\"relu\")(main)\n\n    \n    main = Dropout(dr-0.2, seed = seed)(main)\n    \n    out = Dense(1, activation = \"sigmoid\", \n                kernel_initializer = glorot_uniform(seed = seed))(main)\n#     model = Model(inputs = [inp, num_input], outputs = out)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\",\n                  optimizer = Adam(), \n                  metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7feab57e0a2882f1847f41604e1c8884494c45c"
      },
      "cell_type": "code",
      "source": "units, dr = 62, 0.3\nnum_capsules = 10\ndim_capsules = 10\nrouts = 4\nmodel = build_capsule_model(units = 40, dr = 0.3, \n                            num_capsules = 10, dim_capsules = 10, routs = 4)\ncapsule_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                         validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9baf01b4f8f0d0fe52b831bc4efde041cad57648"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2f2afef848895dc6f67906d8ec933cbbbb067c2d"
      },
      "cell_type": "markdown",
      "source": "## RWA Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de2a5021879277529aa8878703a64f98130d3522"
      },
      "cell_type": "code",
      "source": "import numpy as np\n\nfrom keras.layers import Recurrent\nimport keras.backend as K\nfrom keras import activations\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.engine import Layer\nfrom keras.engine import InputSpec\nfrom keras.legacy import interfaces\n\n\nclass RWA(Recurrent):\n    \"\"\"\n    # References\n     - [Machine Learning on Sequential Data Using a Recurrent Weighted Average](https://arxiv.org/abs/1703.01253)\n    \"\"\"\n    @interfaces.legacy_recurrent_support\n    def __init__(self, units,\n                 activation='tanh',\n                 recurrent_activation='tanh',\n                 features_initializer='glorot_uniform',\n                 recurrent_initializer='glorot_uniform',\n                 average_initializer = 'glorot_uniform',\n                 initial_attention_initializer = 'zeros',\n                 bias_initializer='zeros',\n                 features_regularizer=None,\n                 recurrent_regularizer=None,\n                 average_regularizer=None,\n                 initial_attention_regularizer = None,\n                 bias_regularizer=None,\n                 features_constraint=None,\n                 recurrent_constraint=None,\n                 average_constraint=None,\n                 initial_attention_constraint = None,\n                 bias_constraint=None,\n#                  dropout=0.,\n#                  recurrent_dropout=0.,\n                 **kwargs):\n        super(RWA, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.features_initializer = initializers.get(features_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.average_initializer = initializers.get(average_initializer)\n        self.initial_attention_initializer = initializers.get(initial_attention_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.features_regularizer = regularizers.get(features_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.average_regularizer = regularizers.get(average_regularizer)\n        self.initial_attention_regularizer = regularizers.get(initial_attention_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.features_constraint = constraints.get(features_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.average_constraint = constraints.get(average_constraint)\n        self.initial_attention_constraint = constraints.get(initial_attention_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.go_backwards = False\n        self.supports_masking = False\n        self.unroll = False\n        # self.return_sequences = False\n        self.stateful = False\n\n#         self.dropout = min(1., max(0., dropout))\n#         self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if initial_state is not None:\n            if not isinstance(initial_state, (list, tuple)):\n                initial_states = [initial_state]\n            else:\n                initial_states = list(initial_state)\n        if isinstance(inputs, list):\n            initial_states = inputs[1:]\n            inputs = inputs[0]\n        else:\n            initial_states = self.get_initial_states(inputs)\n\n        if len(initial_states) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_states)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n        h = initial_states[0]\n        h+= self.recurrent_activation(self.initial_attention)\n        initial_states[0]=h\n        last_output, outputs, states = K.rnn(self.step,\n                                             preprocessed_input,\n                                             initial_states,\n                                             go_backwards=self.go_backwards,\n                                             mask=mask,\n                                             constants=constants,\n                                             unroll=self.unroll,\n                                             input_length=input_shape[1])\n        # return last_output\n#         if self.stateful:\n#             updates = []\n#             for i in range(len(states)):\n#                 updates.append((self.states[i], states[i]))\n#             self.add_update(updates, inputs)\n\n        # Properly set learning phase\n#         if 0 < self.dropout + self.recurrent_dropout:\n#             last_output._uses_learning_phase = True\n#             outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            return outputs\n        else:\n            return last_output\n\n    # def compute_output_shape(self, input_shape):\n    #     if isinstance(input_shape, list):\n    #         input_shape = input_shape[0]\n    #     return (input_shape[0], self.units)\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_dim = input_shape[2]\n        self.input_spec[0] = InputSpec(shape=(batch_size, None, self.input_dim))\n        #states: h, d, n, a_max\n        state_shape = (batch_size, None, self.units) if self.stateful else (batch_size, self.units)\n        self.state_spec = [InputSpec(shape=state_shape),\n                           InputSpec(shape=state_shape),\n                          InputSpec(shape=state_shape),\n                          InputSpec(shape=state_shape)]\n\n        self.states = [None, None, None, None]\n        #W_u and b_u\n        self.features_kernel = self.add_weight((self.input_dim, self.units),\n                                      name='features_kernel',\n                                      initializer=self.features_initializer,\n                                      regularizer=self.features_regularizer,\n                                      constraint=self.features_constraint)\n        self.features_bias = self.add_weight((self.units,),\n                                        name='features_bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        #W_g and b_g\n\n        self.recurrent_kernel = self.add_weight(\n                                        (self.input_dim+self.units, self.units),\n                                        name='recurrent_kernel',\n                                        initializer=self.recurrent_initializer,\n                                        regularizer=self.recurrent_regularizer,\n                                        constraint=self.recurrent_constraint)\n        self.recurrent_bias = self.add_weight((self.units,),\n                                        name='recurrent_bias',\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        #W_a\n        self.average_kernel = self.add_weight(\n                                        (self.input_dim+self.units, self.units),\n                                        name='average_kernel',\n                                        initializer=self.average_initializer,\n                                        regularizer=self.average_regularizer,\n                                        constraint=self.average_constraint)\n\n        #s\n\n        self.initial_attention = self.add_weight((self.units, ),\n                                        name='initial_attention',\n                                        initializer=self.initial_attention_initializer,\n                                        regularizer=self.initial_attention_regularizer,\n                                        constraint=self.initial_attention_constraint)\n\n        self.built = True\n\n    def preprocess_input(self, inputs, training=None):\n        return inputs\n\n    def get_initial_states(self, inputs):\n        #states: h, d, n, a_max\n        # build an all-zero tensor of shape (samples, output_dim)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, output_dim)\n        initial_states = [initial_state for _ in range(len(self.states)-1)]\n\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])\n        dtype = initial_state.dtype.name\n        min_value = np.asscalar(np.array([1E38]).astype(dtype))\n        initial_state = initial_state - min_value\n        initial_states.append(initial_state)\n        return initial_states\n\n    def get_constants(self, inputs, training=None):\n        constants = []\n        return constants\n\n    def step(self, inputs, states):\n        h = states[0]\n        d = states[1]\n        n = states[2]\n        a_max = states[3]\n#         dp_mask = states[2]\n#         rec_dp_mask = states[3]\n        inputs_joined = K.concatenate([inputs, h], axis=-1)\n        u = K.dot(inputs,self.features_kernel)\n        u = K.bias_add(u, self.features_bias)\n\n        g = K.dot(inputs_joined, self.recurrent_kernel)\n        g = K.bias_add(g, self.recurrent_bias)\n\n        a = K.dot(inputs_joined, self.average_kernel)\n\n        z = u * self.recurrent_activation(g)\n\n        a_newmax = K.maximum(a_max, a)\n        exp_diff = K.exp(a_max - a_newmax)\n        exp_scaled = K.exp(a - a_newmax)\n\n        n = n*exp_diff + z*exp_scaled\n        d = d*exp_diff + exp_scaled\n        h_new = self.activation(n/d)\n        a_max = a_newmax\n        h = h_new\n\n        return h, [h, d, n, a_max]\n\n    def get_config(self):\n        config = {'units': self.units,\n                  'activation': activations.serialize(self.activation),\n                  'recurrent_activation': activations.serialize(self.recurrent_activation),\n                  'features_initializer': initializers.serialize(self.features_initializer),\n                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n                  'average_initializer': initializers.serialize(self.average_initializer),\n                  'initial_attention_initializer':  initializers.serialize(self.initial_attention_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'features_regularizer': regularizers.serialize(self.features_regularizer),\n                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n                    'average_regularizer': regularizers.serialize(self.average_regularizer),\n                    'initial_attention_regularizer': regularizers.serialize(self.initial_attention_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'features_constraint': constraints.serialize(self.features_constraint),\n                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n                  'average_constraint': constraints.serialize(self.average_constraint),\n                  'initial_attention_constraint': constraints.serialize(self.initial_attention_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n#                   'dropout': self.dropout,\n#                   'recurrent_dropout': self.recurrent_dropout\n                 }\n        base_config = super(RWA, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0157b365b10f1e5aed1d3a95d7ea4110521604ee"
      },
      "cell_type": "code",
      "source": "def build_rwa_model(units = 40, dr = 0.3):\n    inp = Input(shape = (max_len, ))\n#     num_input = Input(shape = (num_feat.shape[1], ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr, seed = seed)(embed_layer)\n    x = Bidirectional(RWA(units, return_sequences = True))(x)\n    x = Capsule(5, 5)(x)\n    max_ = GlobalMaxPooling1D()(x)\n    avg_ = GlobalAveragePooling1D()(x)\n    \n    main = concatenate([max_, avg_])\n    main = Dense(128)(main)\n    main = Activation(\"relu\")(main)\n#     main = BatchNormalization()(main)\n\n    main = Dropout(dr-0.2, seed = seed)(main)\n    \n    out = Dense(1, activation = \"sigmoid\")(main)\n#     model = Model(inputs = [inp, num_input], outputs = out)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\",\n                  optimizer = Adam(), \n                  metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4fbbee149f5776be36f96f58ca3ae0e5480eff30"
      },
      "cell_type": "code",
      "source": "model = build_rwa_model(units = 64, dr = 0.3)\nrwa_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                     validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c776017b3f93b9543b43675d28a6ce8c2a1bc3cf"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d411bb4efa332623d471fd033384103a0751d04b"
      },
      "cell_type": "markdown",
      "source": "### DPCNN Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d809bb7ccfd87224d139c7bb8207b87c0c817a4"
      },
      "cell_type": "code",
      "source": "from keras.layers import PReLU, add\n\nact, pad, kernel_ini = \"linear\", \"same\", \"he_uniform\"\ndef build_dpcnn_model(units = 0, k = 0, num_block = 0, dr = 0.0):\n    inp = Input(shape = (max_len, ))\n    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n                    input_length = max_len, trainable = False)(inp)\n    emb = SpatialDropout1D(dr)(emb)\n    emb_short_cut = PReLU()(emb)\n    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = act,\n                           kernel_initializer = kernel_ini)(emb_short_cut)\n    emb_short_cut = PReLU()(emb_short_cut)\n    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = act,\n                           kernel_initializer = kernel_ini)(emb_short_cut)\n    \n    # Main block\n    for b in range(1, num_block + 1):\n        if b == 1:\n            block = emb\n            short_cut = emb_short_cut\n        else:\n            block = block\n            short_cut = block\n                    \n#         block = BatchNormalization()(block)\n        block = PReLU()(block)\n        block = Conv1D(units, kernel_size = k, padding = pad, activation = act, \n                       kernel_initializer = kernel_ini)(block)\n#         block = BatchNormalization()(block)\n        block = PReLU()(block)\n        block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n                      kernel_initializer = kernel_ini)(block)\n        block = add([short_cut, block])\n        block = MaxPooling1D(pool_size = 3, strides = 2, padding = pad)(block)\n        \n    # Final block\n    short_cut = block\n#     block = BatchNormalization()(block)\n    block = PReLU()(block)\n    block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n                  kernel_initializer = kernel_ini)(block)\n#     block = BatchNormalization()(block)\n    block = PReLU()(block)\n    block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n                  kernel_initializer = kernel_ini)(block)\n    block = add([short_cut, block])\n    max_pool = GlobalMaxPooling1D()(block)\n    avg_pool = GlobalAveragePooling1D()(block)\n    block = concatenate([max_pool, avg_pool])\n    \n    # output block\n    out_put = Dense(128, activation = act)(block)\n#     out_put = BatchNormalization()(out_put)\n    out_put = PReLU()(out_put)\n    out_put = Dense(64, activation = act)(block)\n#     out_put = BatchNormalization()(out_put)\n    out_put = PReLU()(out_put)\n    \n    out_put = Dense(1, activation = \"sigmoid\")(out_put)\n    model = Model(inputs = inp, outputs = out_put)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b369e47f2fdc8f631f0bff7153d157fc2f1bbacb"
      },
      "cell_type": "code",
      "source": "model = build_dpcnn_model(units = 64, k = 3, num_block = 3, dr = 0.3)\ndpcnn_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                       validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9290601d530903f610eb7bc420fd0573c09178bd"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22b544ce6dcd55ff26ceb9369410c2c6a161ab82"
      },
      "cell_type": "markdown",
      "source": "### QRNN Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f0fddb5138d2a4b77bba26c42ce06ef6e6ea95fd"
      },
      "cell_type": "code",
      "source": "from keras.layers import Wrapper\nimport keras.backend as K\n\nclass DropConnect(Wrapper):\n    def __init__(self, layer, prob=1., **kwargs):\n        self.prob = prob\n        self.layer = layer\n        super(DropConnect, self).__init__(layer, **kwargs)\n        if 0. < self.prob < 1.:\n            self.uses_learning_phase = True\n\n    def build(self, input_shape):\n        if not self.layer.built:\n            self.layer.build(input_shape)\n            self.layer.built = True\n        super(DropConnect, self).build()\n\n    def compute_output_shape(self, input_shape):\n        return self.layer.compute_output_shape(input_shape)\n\n    def call(self, x):\n        if 0. < self.prob < 1.:\n            self.layer.kernel = K.in_train_phase(K.dropout(self.layer.kernel, self.prob), self.layer.kernel)\n            self.layer.bias = K.in_train_phase(K.dropout(self.layer.bias, self.prob), self.layer.bias)\n        return self.layer.call(x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6719e77ae18185313809ff57e443bc7c48c6112"
      },
      "cell_type": "code",
      "source": "from keras import backend as K\nfrom keras import activations, initializers, regularizers, constraints\nfrom keras.layers import Layer, InputSpec\nfrom keras.utils.conv_utils import conv_output_length\n\ndef _dropout(x, level, noise_shape=None, seed=None):\n    x = K.dropout(x, level, noise_shape, seed)\n    x *= (1. - level) # compensate for the scaling by the dropout\n    return x\n\nclass QRNN(Layer):\n    '''Quasi RNN\n    # Arguments\n        units: dimension of the internal projections and the final output.\n    # References\n        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n    '''\n    def __init__(self, units, window_size=2, stride=1,\n                 return_sequences=False, go_backwards=False, \n                 stateful=False, unroll=False, activation='tanh',\n                 kernel_initializer='uniform', bias_initializer='zero',\n                 kernel_regularizer=None, bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None, bias_constraint=None, \n                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n                 **kwargs):\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.units = units \n        self.window_size = window_size\n        self.strides = (stride, 1)\n\n        self.use_bias = use_bias\n        self.activation = activations.get(activation)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = dropout\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.input_dim = input_dim\n        self.input_length = input_length\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_length, self.input_dim)\n        super(QRNN, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_dim = input_shape[2]\n        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n        self.state_spec = InputSpec(shape=(batch_size, self.units))\n\n        self.states = [None]\n        if self.stateful:\n            self.reset_states()\n\n        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n        self.kernel = self.add_weight(name='kernel',\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(name='bias', \n                                        shape=(self.units * 3,),\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        length = input_shape[1]\n        if length:\n            length = conv_output_length(length + self.window_size - 1,\n                                        self.window_size, 'valid',\n                                        self.strides[0])\n        if self.return_sequences:\n            return (input_shape[0], length, self.units)\n        else:\n            return (input_shape[0], self.units)\n\n    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            return mask\n        else:\n            return None\n\n    def get_initial_states(self, inputs):\n        # build an all-zero tensor of shape (samples, units)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n        initial_states = [initial_state for _ in range(len(self.states))]\n        return initial_states\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        if not self.input_spec:\n            raise RuntimeError('Layer has never been called '\n                               'and thus has no states.')\n\n        batch_size = self.input_spec.shape[0]\n        if not batch_size:\n            raise ValueError('If a QRNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 'state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, self.units)) +\n                                     ', found shape=' + str(value.shape))\n                K.set_value(state, value)\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is not None:\n            if hasattr(initial_state, '_keras_history'):\n                # Compute the full input spec, including state\n                input_spec = self.input_spec\n                state_spec = self.state_spec\n                if not isinstance(state_spec, list):\n                    state_spec = [state_spec]\n                self.input_spec = [input_spec] + state_spec\n\n                # Compute the full inputs, including state\n                if not isinstance(initial_state, (list, tuple)):\n                    initial_state = [initial_state]\n                inputs = [inputs] + list(initial_state)\n\n                # Perform the call\n                output = super(QRNN, self).__call__(inputs, **kwargs)\n\n                # Restore original input spec\n                self.input_spec = input_spec\n                return output\n            else:\n                kwargs['initial_state'] = initial_state\n        return super(QRNN, self).__call__(inputs, **kwargs)\n\n    def call(self, inputs, mask=None, initial_state=None, training=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_states = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_states = self.states\n        else:\n            initial_states = self.get_initial_states(inputs)\n\n        if len(initial_states) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_states)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        if self.unroll and input_shape[1] is None:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n\n        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n                                            initial_states,\n                                            go_backwards=self.go_backwards,\n                                            mask=mask,\n                                            constants=constants,\n                                            unroll=self.unroll,\n                                            input_length=input_shape[1])\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout < 1:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            return outputs\n        else:\n            return last_output\n\n    def preprocess_input(self, inputs, training=None):\n        if self.window_size > 1:\n            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n\n        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n                          padding='valid',\n                          data_format='channels_last')\n        output = K.squeeze(output, 2)  # remove the dummy dimension\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format='channels_last')\n\n        if self.dropout is not None and 0. < self.dropout < 1.:\n            z = output[:, :, :self.units]\n            f = output[:, :, self.units:2 * self.units]\n            o = output[:, :, 2 * self.units:]\n            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n            return K.concatenate([z, f, o], -1)\n        else:\n            return output\n\n    def step(self, inputs, states):\n        prev_output = states[0]\n\n        z = inputs[:, :self.units]\n        f = inputs[:, self.units:2 * self.units]\n        o = inputs[:, 2 * self.units:]\n\n        z = self.activation(z)\n        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n        o = K.sigmoid(o)\n\n        output = f * prev_output + (1 - f) * z\n        output = o * output\n\n        return output, [output]\n\n    def get_constants(self, inputs, training=None):\n        return []\n \n    def get_config(self):\n        config = {'units': self.units,\n                  'window_size': self.window_size,\n                  'stride': self.strides[0],\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'use_bias': self.use_bias,\n                  'dropout': self.dropout,\n                  'activation': activations.serialize(self.activation),\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'input_dim': self.input_dim,\n                  'input_length': self.input_length}\n        base_config = super(QRNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7de6fd07d1b968dd5e1d98503cf3c87d952c36d"
      },
      "cell_type": "code",
      "source": "def build_qrnn_model(units = 40, dr = 0.3):\n    inp = Input(shape = (max_len, ))\n#     num_input = Input(shape = (num_feat.shape[1], ))\n    embed_layer = Embedding(nb_words, embed_size, input_length = max_len,\n                            weights = [embedding_matrix], trainable = False)(inp)\n    \n    x = SpatialDropout1D(dr, seed = seed)(embed_layer)\n    x = QRNN(units, window_size = 3, stride = 1, return_sequences = True)(x)\n    x = DropConnect(QRNN(units, window_size = 3, stride = 1, return_sequences = True), \n                    prob = dr)(x)\n    x = DropConnect(QRNN(units, window_size = 3, stride = 1, return_sequences = True), \n                    prob = dr)(x)\n    att_ = Attention(max_len)(x)\n    max_ = GlobalMaxPooling1D()(x)\n    avg_ = GlobalAveragePooling1D()(x)\n    \n    main = concatenate([att_, max_, avg_])\n    main = DropConnect(Dense(128, activation = \"relu\"),\n                       prob = dr)(main)\n    \n    out = Dense(1, activation = \"sigmoid\")(main)\n    model = Model(inputs = inp, outputs = out)\n    model.compile(loss = \"binary_crossentropy\",\n                  optimizer = Adam(), \n                  metrics = [\"accuracy\"])\n    \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cfb1ed4516abe699bd70600e87a9dbbe99360746"
      },
      "cell_type": "code",
      "source": "model = build_qrnn_model(units = 62, dr = 0.3)\nqrnn_hist = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n                      validation_data = (X_val, y_val), verbose = 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53b1243fde445aa37eacdc51497cce3068518337"
      },
      "cell_type": "code",
      "source": "val_pred = model.predict(X_val, batch_size = 256, verbose = 1)\n\nthreshold, score = threshold_search(y_val, val_pred)\nprint(\"F1 score at threshold {0} is {1}\".format(threshold, score))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "720b416dfd92fb41848433e3f8d879342166543b"
      },
      "cell_type": "markdown",
      "source": "Without using DropConnect layers between QRNN layers, model performance is terrible."
    },
    {
      "metadata": {
        "_uuid": "d2219cb82c5417c0e8c648a1fa389e5a0f586050"
      },
      "cell_type": "markdown",
      "source": "## Model Evaluation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "acd5a49f3926e19be5e2e539bd4ed75221bd63db"
      },
      "cell_type": "code",
      "source": "models_hist = {\"simple_lstm\": slstm_hist, \n               \"double_lstm\": dlstm_hist,\n               \"rnn\": rnn_hist,\n               \"rcnn\": rcnn_hist,\n               \"double_lstm_with_pooling\": dlstm_pool_hist,\n               \"capsule_net\": capsule_hist,\n               \"rwa\": rwa_hist,\n               \"dpcnn\": dpcnn_hist,\n               \"qrnn\": qrnn_hist}\n\nplt.figure(figsize = (10, 8))\nfor hist in models_hist: \n    plt.plot(models_hist[hist].history[\"acc\"])\nplt.title(\"Model Train Accuracy\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend(models_hist.keys(), loc = \"upper left\")\nplt.savefig(\"Train_Accuracy.png\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nfor hist in models_hist: \n    plt.plot(models_hist[hist].history[\"val_acc\"])\nplt.title(\"Model Val Accuracy\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend(models_hist.keys(), loc = \"upper left\")\nplt.savefig(\"Val_Accuracy.png\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b98d91876fab2f94d63f306c50d30ac178fe8f52"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize = (10, 8))\nfor hist in models_hist: \n    plt.plot(models_hist[hist].history[\"loss\"])\nplt.title(\"Model Train Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend(models_hist.keys(), loc = \"upper left\")\nplt.savefig(\"Train_Loss.png\")\nplt.show()\n\nplt.figure(figsize = (10, 8))\nfor hist in models_hist: \n    plt.plot(models_hist[hist].history[\"val_loss\"])\nplt.title(\"Model Val Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend(models_hist.keys(), loc = \"upper left\")\nplt.savefig(\"Val_Loss.png\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b5c74d9031f609a9d305a24533dae46b3e551980"
      },
      "cell_type": "markdown",
      "source": "### Make Prediction"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e142d4438b5b24bbaec15db9a4c2faf7aabe3b6"
      },
      "cell_type": "code",
      "source": "test_pred = model.predict(X_test, verbose = 1)\ntest_pred = (test_pred > threshold).astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "329afb8f739e09043e4cb46836a3dbdadd30f985"
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame({\"qid\": test[\"qid\"]})\nsubmission[\"prediction\"] = test_pred\nsubmission.to_csv(\"submission.csv\", index = False)\nsubmission.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5d08b42e0955321f0544fe035a0e2d8c1e42faf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
