Readings:

* [Identifying Mislabeled Training Data](https://arxiv.org/pdf/1106.0219.pdf)
* [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/pdf/1106.1813.pdf)
* [Latent Dirichlet Allocation](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)
* [Visualizing Data using t-SNE](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)
* [“Why Should I Trust You?” Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf)
* [Sentence Ordering and Coherence Modeling using Recurrent Neural Networks](https://arxiv.org/pdf/1611.02654.pdf)
* [Evolutionary Data Measures: Understanding the Difficulty of Text Classification Tasks](https://arxiv.org/pdf/1811.01910.pdf)

* Meta embedding

  * [Dynamic Meta-Embeddings for Improved Sentence Representations](http://aclweb.org/anthology/D18-1176)
  * [Angular-Based Word Meta-Embedding Learning](https://arxiv.org/pdf/1808.04334.pdf)
  * [Learning Meta-Embeddings by Using Ensembles of Embedding Sets](https://arxiv.org/pdf/1508.04257.pdf)
  
* Text Augmentation

  * [Text Understanding from Scratch](https://arxiv.org/pdf/1502.01710.pdf)
  * [DATA NOISING AS SMOOTHING IN NEURAL NETWORK LANGUAGE MODELS](https://arxiv.org/pdf/1703.02573.pdf))
