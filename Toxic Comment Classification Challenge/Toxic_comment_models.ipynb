{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic comment models.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "N0n40qsaL777",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fKoaYe_11ZdC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Glove\n",
        "# !wget http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip -c\n",
        "# !unzip glove.840B.300d.zip -d glove.840B.300d/\n",
        "\n",
        "# Twitter\n",
        "# !wget http://nlp.stanford.edu/data/glove.twitter.27B.zip -c\n",
        "# !unzip glove.twitter.27B.zip -d glove.twitter.27B.200d/\n",
        "\n",
        "# FastTest\n",
        "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/crawl-300d-2M.vec.zip\n",
        "!unzip crawl-300d-2M.vec.zip -d crawl-300d-2M.vec/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sf-Gemig24Ut",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(32)\n",
        "import pandas as pd\n",
        "\n",
        "! pip install pydrive\n",
        "# these classes allow you to request the Google drive API\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "# https://drive.google.com/open?id=1Rk9F9YUMuG9JtuhCaUck1Lxid3OISc1-\n",
        "file_id = '1Rk9F9YUMuG9JtuhCaUck1Lxid3OISc1-'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "# allows you to temporarily load your file in the notebook VM\n",
        "\n",
        "downloaded.GetContentFile('train.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "\n",
        "# https://drive.google.com/open?id=1CH6MLJYHK6rtC-p_4kK7Ms17CIisowGZ\n",
        "file_id = '1CH6MLJYHK6rtC-p_4kK7Ms17CIisowGZ'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('test.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kyAUqO6SLdQl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def download_file(file_name):\n",
        "  files.download(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ilgm_LWyY7O4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "max_features = 150000 \n",
        "max_text_len = 150\n",
        "\n",
        "# EMBEDDING_FILE = \"glove.840B.300d/glove.840B.300d.txt\"\n",
        "# EMBEDDING_FILE = \"glove.twitter.27B.200d/glove.twitter.27B.200d.txt\"\n",
        "EMBEDDING_FILE = \"crawl-300d-2M.vec/crawl-300d-2M.vec\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ysSiCjAC5yp9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import sys, os, re, csv, codecs, gc\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
        "from keras.layers import Bidirectional, Add, Flatten, add, PReLU, MaxPooling1D\n",
        "from keras.optimizers import Adam, RMSprop, Nadam\n",
        "from keras.layers import SpatialDropout1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
        "from keras.layers import concatenate, GRU, CuDNNGRU, CuDNNLSTM, TimeDistributed\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "\n",
        "import logging\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch + 1, score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTYihaljFnmr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "def pair_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "    parts = tf.dynamic_partition(y_pred, y_true, 2)\n",
        "    y_pos = parts[1]\n",
        "    y_neg = parts[0]\n",
        "    y_pos = tf.expand_dims(y_pos, 0)\n",
        "    y_neg = tf.expand_dims(y_neg, -1)\n",
        "    out = K.sigmoid(y_neg - y_pos)\n",
        "    return K.mean(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lnh5jSXj25jD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def clean_corpus(comment):\n",
        "    comment = comment.lower()\n",
        "    comment = comment.replace('&', ' and ')\n",
        "    comment = comment.replace('0', ' zero ')\n",
        "    comment = comment.replace('1', ' one ')\n",
        "    comment = comment.replace('2', ' two ')\n",
        "    comment = comment.replace('3', ' three ')\n",
        "    comment = comment.replace('4', ' four ')\n",
        "    comment = comment.replace('5', ' five ')\n",
        "    comment = comment.replace('6', ' six ')\n",
        "    comment = comment.replace('7', ' seven ')\n",
        "    comment = comment.replace('8', ' eight ')\n",
        "    comment = comment.replace('9', ' nine ')\n",
        "    comment = comment.replace('\\'ve', ' have ')\n",
        "    comment = comment.replace('\\'d', ' would ')\n",
        "    comment = comment.replace('\\'m', ' am ')\n",
        "    comment = comment.replace('n\\'t', ' not ')\n",
        "    comment = comment.replace('\\'s', ' is ')\n",
        "    comment = comment.replace('\\'r', ' are ')\n",
        "    comment = nltk.word_tokenize(comment)\n",
        "    comment = \" \".join(word for word in comment)\n",
        "    return comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4X6QfBsr6Lza",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "category = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "train[\"comment_text\"].fillna(\"no comment\", inplace = True)\n",
        "train[\"comment_text\"] = train[\"comment_text\"].apply(lambda x: clean_corpus(x))\n",
        "\n",
        "test[\"comment_text\"].fillna(\"no comment\", inplace = True)\n",
        "test[\"comment_text\"] = test[\"comment_text\"].apply(lambda x: clean_corpus(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BknDKiY46P3t",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "nrow_train = train.shape[0]\n",
        "Y_train = train[category].values\n",
        "\n",
        "k_fold = True\n",
        "if k_fold:\n",
        "  print(\"Doing K fold!\")\n",
        "  raw_text_train = train[\"comment_text\"].str.lower()\n",
        "  raw_text_test = test[\"comment_text\"].str.lower()\n",
        "\n",
        "  tk = Tokenizer(num_words = max_features, lower = True)\n",
        "  tk.fit_on_texts(raw_text_train)\n",
        "\n",
        "  train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train.str.lower())\n",
        "  test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test.str.lower())\n",
        "\n",
        "  X_train = pad_sequences(train.comment_seq, maxlen = max_text_len)\n",
        "  X_test = pad_sequences(test.comment_seq, maxlen = max_text_len)\n",
        "\n",
        "else:\n",
        "  print(\"Tuning model!\")\n",
        "  X_train, X_valid, Y_train, Y_valid = train_test_split(train, Y_train, test_size = 0.1)\n",
        "  raw_text_train = X_train[\"comment_text\"].str.lower()\n",
        "  raw_text_valid = X_valid[\"comment_text\"].str.lower()\n",
        "  raw_text_test = test[\"comment_text\"].str.lower()\n",
        "  \n",
        "  tk = Tokenizer(num_words = max_features, lower = True)\n",
        "  tk.fit_on_texts(raw_text_train)\n",
        "\n",
        "  X_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train.str.lower())\n",
        "  X_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid.str.lower())\n",
        "  test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test.str.lower())\n",
        "\n",
        "  X_train = pad_sequences(X_train.comment_seq, maxlen = max_text_len)\n",
        "  X_valid = pad_sequences(X_valid.comment_seq, maxlen = max_text_len)\n",
        "  X_test = pad_sequences(test.comment_seq, maxlen = max_text_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HepYIvXs6TyV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype = \"float32\")\n",
        "embeddings_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUmJY4wH6VlO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# all_embs = np.stack(embeddings_index.values())\n",
        "# emb_mean,emb_std = all_embs.mean(), all_embs.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyMVw25U6WPL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tk.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "# embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0E1DRsN46X_J",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def build_LSTM_model(units = 0, dr = 0.0, lr_i = 0.0, lr_f = 0.0):\n",
        "  inp = Input(shape = (max_text_len,))\n",
        "  main = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
        "                   input_length = max_text_len, trainable = False)(inp)\n",
        "  \n",
        "  main = SpatialDropout1D(dr)(main)\n",
        "  main = Bidirectional(CuDNNLSTM(units, return_sequences = True))(main)\n",
        "  atten = AttentionWeightedAverage()(main)\n",
        "  cnn = Conv1D(64, kernel_size = 3, padding = \"same\", kernel_initializer = \"he_uniform\", activation = \"elu\")(main)\n",
        "  avg_pool = GlobalAveragePooling1D()(cnn)\n",
        "  max_pool = GlobalMaxPooling1D()(cnn)\n",
        "  main = concatenate([atten, avg_pool, max_pool])\n",
        "  \n",
        "  out_put = Dense(6, activation = \"sigmoid\")(main)\n",
        "  model = Model(inputs = inp, outputs = out_put)\n",
        "  model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr_i, decay = lr_f), metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p63b6BlT6Zyn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "batch_sizes = 128\n",
        "epochs = 10\n",
        "units = 128\n",
        "dr = 0.3\n",
        "lr_i, lr_f = 1e-3, 0\n",
        "n_folds = 10\n",
        "lstm_pred = 0\n",
        "lstm_oof_pred = np.zeros((nrow_train, 6))\n",
        "val_losses = []\n",
        "\n",
        "kfold = KFold(n_splits = n_folds, shuffle = True, random_state = 32)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n",
        "  print(\"\\nRunning fold {}/{}\".format(i + 1, n_folds))\n",
        "  model = None\n",
        "  model = build_LSTM_model(units = units, dr = dr, lr_i = lr_i, lr_f = lr_f)\n",
        "  \n",
        "  x_train, y_train = X_train[train_idx], Y_train[train_idx] \n",
        "  x_valid, y_valid = X_train[valid_idx], Y_train[valid_idx]\n",
        "  \n",
        "  ra_val = RocAucEvaluation(validation_data = (x_valid, y_valid), interval = 1)\n",
        "\n",
        "  file_path = \"fold \" + str(i+1) + \" best_model.hdf5\"\n",
        "  check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                save_best_only = True, mode = \"min\")\n",
        "  \n",
        "  hist = model.fit(x_train, y_train, batch_size = batch_sizes, epochs = epochs, validation_data = (x_valid, y_valid), \n",
        "                   verbose = 2, callbacks = [check_point, early_stop, ra_val])\n",
        "  val_losses.append(min(hist.history[\"val_loss\"]))\n",
        "  model = load_model(file_path, custom_objects = {\"AttentionWeightedAverage\": AttentionWeightedAverage})\n",
        "  lstm_pred += model.predict(X_test, batch_size = batch_sizes, verbose = 2)\n",
        "  lstm_oof_pred[valid_idx] = model.predict(x_valid, batch_size = batch_sizes, verbose = 2)\n",
        "  \n",
        "  del file_path, model\n",
        "  gc.collect()\n",
        "\n",
        "lstm_pred = lstm_pred/n_folds\n",
        "print(\"\\noof score of lstm is {}.\".format(roc_auc_score(Y_train, lstm_oof_pred)))\n",
        "print(\"\\nAverage val loss of {} folds is {}.\".format(n_folds, np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xv0ggvIHn7AK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lstm_submission = pd.DataFrame()\n",
        "lstm_submission = lstm_submission.reindex(columns = [\"id\"] + category)\n",
        "lstm_submission[\"id\"]= test[[\"id\"]]\n",
        "lstm_submission[category[0:6]] = lstm_pred\n",
        "lstm_submission.to_csv(\"lstm_submission.csv\", index = False)\n",
        "download_file(\"lstm_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-tCAz00Vn98A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lstm_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVyBjGbwNIAW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lstm_oof_prediction = pd.DataFrame()\n",
        "lstm_oof_prediction = lstm_oof_prediction.reindex(columns = [\"id\"] + category)\n",
        "lstm_oof_prediction[\"id\"]= train[[\"id\"]]\n",
        "lstm_oof_prediction[category[0:6]] = pd.DataFrame(lstm_oof_pred)\n",
        "lstm_oof_prediction.to_csv(\"lstm_oof_prediction.csv\", index = False)\n",
        "download_file(\"lstm_oof_prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zrvtFURMPu8Q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def build_GRU_model(units = 0, dr = 0.0):\n",
        "  inp = Input(shape = (max_text_len,))\n",
        "  main = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
        "                   input_length = max_text_len, trainable = False)(inp)\n",
        "  \n",
        "  main = SpatialDropout1D(dr)(main)\n",
        "  main = Bidirectional(CuDNNGRU(units, return_sequences = True))(main)\n",
        "  main = AttentionWeightedAverage()(main)\n",
        "  main = Dense(64, activation = \"relu\")(main)\n",
        "  \n",
        "  out_put = Dense(6, activation = \"sigmoid\")(main)\n",
        "  model = Model(inputs = inp, outputs = out_put)\n",
        "    \n",
        "  model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = 1e-3), metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "batch_sizes = 128\n",
        "epochs = 10\n",
        "units = 128\n",
        "dr = 0.2\n",
        "n_folds = 10\n",
        "gru_pred = 0\n",
        "gru_oof_pred = np.zeros((nrow_train, 6))\n",
        "val_losses = []\n",
        "\n",
        "kfold = KFold(n_splits = n_folds, shuffle = True, random_state = 32)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n",
        "  print(\"\\nRunning fold {}/{}\".format(i + 1, n_folds))\n",
        "  model = None\n",
        "  model = build_GRU_model(units = units, dr = dr)\n",
        "  \n",
        "  x_train, y_train = X_train[train_idx], Y_train[train_idx] \n",
        "  x_valid, y_valid = X_train[valid_idx], Y_train[valid_idx]\n",
        "  \n",
        "  ra_val = RocAucEvaluation(validation_data = (x_valid, y_valid), interval = 1)\n",
        "\n",
        "  file_path = \"fold \" + str(i+1) + \" best_model.hdf5\"\n",
        "  check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                save_best_only = True, mode = \"min\")\n",
        "  \n",
        "  hist = model.fit(x_train, y_train, batch_size = batch_sizes, epochs = epochs, validation_data = (x_valid, y_valid), \n",
        "                      verbose = 2, callbacks = [check_point, early_stop, ra_val])\n",
        "  model = load_model(file_path, custom_objects = {\"AttentionWeightedAverage\": AttentionWeightedAverage})\n",
        "  val_losses.append(min(hist.history[\"val_loss\"]))\n",
        "  gru_pred += model.predict(X_test, batch_size = batch_sizes, verbose = 2)  \n",
        "  gru_oof_pred[valid_idx] = model.predict(x_valid, batch_size = batch_sizes, verbose = 2)\n",
        "  \n",
        "  del file_path, model\n",
        "  gc.collect()\n",
        "  \n",
        "gru_pred = gru_pred/n_folds\n",
        "print(\"\\noof score of gru is {}.\".format(roc_auc_score(Y_train, gru_oof_pred)))\n",
        "print(\"\\nAverage val loss of {} folds is {}.\".format(n_folds, np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1-EWgQ26cdN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "gru_submission = pd.DataFrame()\n",
        "gru_submission = gru_submission.reindex(columns = [\"id\"] + category)\n",
        "gru_submission[\"id\"]= test[[\"id\"]]\n",
        "gru_submission[category[0:6]] = gru_pred\n",
        "gru_submission.to_csv(\"gru_submission.csv\", index = False)\n",
        "download_file(\"gru_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oal0btx_Df4e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "gru_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3yZeOAoPIOA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "gru_oof_prediction = pd.DataFrame()\n",
        "gru_oof_prediction = gru_oof_prediction.reindex(columns = [\"id\"] + category)\n",
        "gru_oof_prediction[\"id\"]= train[[\"id\"]]\n",
        "gru_oof_prediction[category[0:6]] = pd.DataFrame(gru_oof_pred)\n",
        "gru_oof_prediction.to_csv(\"gru_oof_prediction.csv\", index = False)\n",
        "download_file(\"gru_oof_prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01Onsc_DDOm3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "gru_oof_prediction.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cJzhf4cQQaAv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def build_rcnn_model(units = 0, dr = 0.0, lr_i = 0.0, lr_f = 0.0):\n",
        "  inp = Input(shape = (max_text_len,))\n",
        "  main = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
        "                   input_length = max_text_len, trainable = False)(inp)\n",
        "  \n",
        "  main = SpatialDropout1D(dr)(main)\n",
        "  main = Bidirectional(CuDNNGRU(units, return_sequences = True))(main)\n",
        "  cnn = Conv1D(64, kernel_size = 3, padding = \"same\", kernel_initializer = \"he_uniform\", activation = \"elu\")(main)\n",
        "  avg_pool = GlobalAveragePooling1D()(cnn)\n",
        "  max_pool = GlobalMaxPooling1D()(cnn)\n",
        "  main = concatenate([avg_pool, max_pool])\n",
        "  \n",
        "  out_put = Dense(6, activation = \"sigmoid\")(main)\n",
        "  model = Model(inputs = inp, outputs = out_put)\n",
        "  model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr_i, decay = lr_f), metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z6x4N-wtQnkO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "batch_sizes = 128\n",
        "epochs = 10\n",
        "units = 128\n",
        "dr = 0.3\n",
        "lr_i, lr_f = 1e-3, 0\n",
        "n_folds = 10\n",
        "rcnn_pred = 0\n",
        "rcnn_oof_pred = np.zeros((nrow_train, 6))\n",
        "val_losses = []\n",
        "\n",
        "kfold = KFold(n_splits = n_folds, shuffle = True, random_state = 32)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n",
        "  print(\"\\nRunning fold {}/{}\".format(i + 1, n_folds))\n",
        "  model = None\n",
        "  model = build_rcnn_model(units = units, dr = dr, lr_i = lr_i, lr_f = lr_f)\n",
        "  \n",
        "  x_train, y_train = X_train[train_idx], Y_train[train_idx] \n",
        "  x_valid, y_valid = X_train[valid_idx], Y_train[valid_idx]\n",
        "  \n",
        "  ra_val = RocAucEvaluation(validation_data = (x_valid, y_valid), interval = 1)\n",
        "\n",
        "  file_path = \"fold \" + str(i+1) + \" best_model.hdf5\"\n",
        "  check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                save_best_only = True, mode = \"min\")\n",
        "  \n",
        "  hist = model.fit(x_train, y_train, batch_size = batch_sizes, epochs = epochs, validation_data = (x_valid, y_valid), \n",
        "                   verbose = 2, callbacks = [check_point, early_stop, ra_val])\n",
        "  val_losses.append(min(hist.history[\"val_loss\"]))\n",
        "  model = load_model(file_path, custom_objects = {\"AttentionWeightedAverage\": AttentionWeightedAverage})\n",
        "  rcnn_pred += model.predict(X_test, batch_size = batch_sizes, verbose = 2)\n",
        "  rcnn_oof_pred[valid_idx] = model.predict(x_valid, batch_size = batch_sizes, verbose = 2)\n",
        "  \n",
        "  del file_path, model\n",
        "  gc.collect()\n",
        "\n",
        "rcnn_pred = rcnn_pred/n_folds\n",
        "print(\"\\noof score of rcnn is {}.\".format(roc_auc_score(Y_train, rcnn_oof_pred)))\n",
        "print(\"\\nAverage val loss of {} folds is {}.\".format(n_folds, np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWSvRT_oQ8JF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rcnn_submission = pd.DataFrame()\n",
        "rcnn_submission = rcnn_submission.reindex(columns = [\"id\"] + category)\n",
        "rcnn_submission[\"id\"]= test[[\"id\"]]\n",
        "rcnn_submission[category[0:6]] = rcnn_pred\n",
        "rcnn_submission.to_csv(\"rcnn_submission.csv\", index = False)\n",
        "download_file(\"rcnn_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmBoGpP7Du1A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rcnn_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfHIdk4iQ_Yo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rcnn_oof_prediction = pd.DataFrame()\n",
        "rcnn_oof_prediction = rcnn_oof_prediction.reindex(columns = [\"id\"] + category)\n",
        "rcnn_oof_prediction[\"id\"]= train[[\"id\"]]\n",
        "rcnn_oof_prediction[category[0:6]] = pd.DataFrame(rcnn_oof_pred)\n",
        "rcnn_oof_prediction.to_csv(\"rcnn_oof_prediction.csv\", index = False)\n",
        "download_file(\"rcnn_oof_prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ki-dlPNICaE0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "rcnn_oof_prediction.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQLCydsss06F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "act, pad, kernel_ini = \"linear\", \"same\", \"he_uniform\"\n",
        "def build_dpcnn_model(units = 0, k = 0, num_block = 0, lr = 0.0, dr = 0.0):\n",
        "    inp = Input(shape = (max_text_len, ))\n",
        "    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
        "                    input_length = max_text_len, trainable = False)(inp)\n",
        "    emb = SpatialDropout1D(dr)(emb)\n",
        "    emb_short_cut = PReLU()(emb)\n",
        "    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = act,\n",
        "                           kernel_initializer = kernel_ini)(emb_short_cut)\n",
        "    emb_short_cut = PReLU()(emb_short_cut)\n",
        "    emb_short_cut = Conv1D(units, kernel_size = 1, padding = pad, activation = act,\n",
        "                           kernel_initializer = kernel_ini)(emb_short_cut)\n",
        "    \n",
        "    # Main block\n",
        "    for b in range(1, num_block + 1):\n",
        "        if b == 1:\n",
        "            block = emb\n",
        "            short_cut = emb_short_cut\n",
        "        else:\n",
        "            block = block\n",
        "            short_cut = block\n",
        "                    \n",
        "#         block = BatchNormalization()(block)\n",
        "        block = PReLU()(block)\n",
        "        block = Conv1D(units, kernel_size = k, padding = pad, activation = act, \n",
        "                       kernel_initializer = kernel_ini)(block)\n",
        "#         block = BatchNormalization()(block)\n",
        "        block = PReLU()(block)\n",
        "        block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n",
        "                      kernel_initializer = kernel_ini)(block)\n",
        "        block = add([short_cut, block])\n",
        "        block = MaxPooling1D(pool_size = 3, strides = 2, padding = pad)(block)\n",
        "        \n",
        "    # Final block\n",
        "    short_cut = block\n",
        "#     block = BatchNormalization()(block)\n",
        "    block = PReLU()(block)\n",
        "    block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n",
        "                  kernel_initializer = kernel_ini)(block)\n",
        "#     block = BatchNormalization()(block)\n",
        "    block = PReLU()(block)\n",
        "    block = Conv1D(units, kernel_size = k, padding = pad, activation = act,\n",
        "                  kernel_initializer = kernel_ini)(block)\n",
        "    block = add([short_cut, block])\n",
        "    max_pool = GlobalMaxPooling1D()(block)\n",
        "    avg_pool = GlobalAveragePooling1D()(block)\n",
        "    block = concatenate([max_pool, avg_pool])\n",
        "    \n",
        "    # output block\n",
        "    out_put = Dense(64, activation = act)(block)\n",
        "#     out_put = BatchNormalization()(out_put)\n",
        "    out_put = PReLU()(out_put)\n",
        "    out_put = Dense(64, activation = act)(block)\n",
        "#     out_put = BatchNormalization()(out_put)\n",
        "    out_put = PReLU()(out_put)\n",
        "  \n",
        "    out_put = Dense(6, activation = \"sigmoid\")(out_put)\n",
        "    model = Model(inputs = inp, outputs = out_put)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Nadam(lr = lr), metrics = [\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDiuqahVtkjQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_folds = 10\n",
        "dpcnn_pred = 0\n",
        "dpcnn_oof_pred = np.zeros((nrow_train, 6))\n",
        "val_losses = []\n",
        "\n",
        "batch_sizes = 128\n",
        "units, k, num_block, lr, dr, epochs = 256, 3, 5, 1e-3, 0.3, 10\n",
        "\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "kfold = KFold(n_splits = n_folds, shuffle = True, random_state = 32)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n",
        "  print(\"\\nRunning fold {}/{}\".format(i + 1, n_folds))\n",
        "  model = None\n",
        "  model = build_dpcnn_model(units = units, k = k, num_block = num_block, lr = lr, dr = dr)\n",
        "  \n",
        "  x_train, y_train = X_train[train_idx], Y_train[train_idx] \n",
        "  x_valid, y_valid = X_train[valid_idx], Y_train[valid_idx]\n",
        "  \n",
        "  ra_val = RocAucEvaluation(validation_data = (x_valid, y_valid), interval = 1)\n",
        "\n",
        "  file_path = \"fold \" + str(i+1) + \" best_model.hdf5\"\n",
        "  check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                save_best_only = True, mode = \"min\")\n",
        "  \n",
        "  hist = model.fit(x_train, y_train, batch_size = batch_sizes, epochs = epochs, validation_data = (x_valid, y_valid), \n",
        "                   verbose = 2, callbacks = [check_point, early_stop, ra_val])\n",
        "  model = load_model(file_path)\n",
        "  val_losses.append(min(hist.history[\"val_loss\"]))\n",
        "  dpcnn_pred += model.predict(X_test, batch_size = batch_sizes, verbose = 2)\n",
        "  dpcnn_oof_pred[valid_idx] = model.predict(x_valid, batch_size = batch_sizes, verbose = 2)\n",
        "\n",
        "  del file_path, model\n",
        "  gc.collect()\n",
        "  \n",
        "dpcnn_pred = dpcnn_pred/n_folds\n",
        "print(\"\\noof score of dpcnn is {}.\".format(roc_auc_score(Y_train, dpcnn_oof_pred)))\n",
        "print(\"\\nAverage val loss of {} folds is {}.\".format(n_folds, np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWGzVj5LMA7S",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dpcnn_submission = pd.DataFrame()\n",
        "dpcnn_submission = cnn_submission.reindex(columns = [\"id\"] + category)\n",
        "dpcnn_submission[\"id\"]= test[[\"id\"]]\n",
        "dpcnn_submission[category[0:6]] = dpcnn_pred\n",
        "dpcnn_submission.to_csv(\"dpcnn_submission.csv\", index = False)\n",
        "download_file(\"dpcnn_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GTdC_wdCMEOL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dpcnn_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGWCN1yghKZo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dpcnn_oof_prediction = pd.DataFrame()\n",
        "dpcnn_oof_prediction = dpcnn_oof_prediction.reindex(columns = [\"id\"] + category)\n",
        "dpcnn_oof_prediction[\"id\"]= train[[\"id\"]]\n",
        "dpcnn_oof_prediction[category[0:6]] = pd.DataFrame(dpcnn_oof_pred)\n",
        "dpcnn_oof_prediction.to_csv(\"dpcnn_oof_prediction.csv\", index = False)\n",
        "download_file(\"dpcnn_oof_prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9jTcraVTK4G",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def build_d_lstm_model(lr = 0.0, units = 0, dr = 0.0):\n",
        "    inp = Input(shape = (max_text_len, ))\n",
        "    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
        "                    input_length = max_text_len, trainable = False)(inp)\n",
        "    main = SpatialDropout1D(dr)(emb)\n",
        "    main = Bidirectional(CuDNNLSTM(units, return_sequences = True))(main)\n",
        "    main = Bidirectional(CuDNNLSTM(units))(main)    \n",
        "    out_put = Dense(6, activation = \"sigmoid\")(main)\n",
        "    model = Model(inputs = inp, outputs = out_put)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr), metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWD67MzATOkf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "n_folds = 10\n",
        "d_lstm_pred = 0\n",
        "d_lstm_oof_pred = np.zeros((nrow_train, 6))\n",
        "val_losses = []\n",
        "\n",
        "batch_sizes = 128\n",
        "units, lr, dr, epochs = 128, 1e-3, 0.3, 10\n",
        "\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
        "\n",
        "kfold = KFold(n_splits = n_folds, shuffle = True, random_state = 32)\n",
        "for i, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n",
        "  print(\"\\nRunning fold {}/{}\".format(i + 1, n_folds))\n",
        "  model = None\n",
        "  model = build_d_lstm_model(lr = lr, units = units, dr = dr)\n",
        "  \n",
        "  x_train, y_train = X_train[train_idx], Y_train[train_idx] \n",
        "  x_valid, y_valid = X_train[valid_idx], Y_train[valid_idx]\n",
        "  \n",
        "  ra_val = RocAucEvaluation(validation_data = (x_valid, y_valid), interval = 1)\n",
        "\n",
        "  file_path = \"fold \" + str(i+1) + \" best_model.hdf5\"\n",
        "  check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                                save_best_only = True, mode = \"min\")\n",
        "  \n",
        "  hist = model.fit(x_train, y_train, batch_size = batch_sizes, epochs = epochs, validation_data = (x_valid, y_valid), \n",
        "                   verbose = 2, callbacks = [check_point, early_stop, ra_val])\n",
        "  model = load_model(file_path)\n",
        "  val_losses.append(min(hist.history[\"val_loss\"]))\n",
        "  d_lstm_pred += model.predict(X_test, batch_size = batch_sizes, verbose = 2)\n",
        "  d_lstm_oof_pred[valid_idx] = model.predict(x_valid, batch_size = batch_sizes, verbose = 2)\n",
        "\n",
        "  del file_path, model\n",
        "  gc.collect()\n",
        "  \n",
        "d_lstm_pred = d_lstm_pred/n_folds\n",
        "print(\"\\noof score of double lstm is {}.\".format(roc_auc_score(Y_train, d_lstm_oof_pred)))\n",
        "print(\"\\nAverage val loss of {} folds is {}.\".format(n_folds, np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18AxVYYcTL7n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "d_lstm_submission = pd.DataFrame()\n",
        "d_lstm_submission = d_lstm_submission.reindex(columns = [\"id\"] + category)\n",
        "d_lstm_submission[\"id\"]= test[[\"id\"]]\n",
        "d_lstm_submission[category[0:6]] = d_lstm_pred\n",
        "d_lstm_submission.to_csv(\"d_lstm_submission.csv\", index = False)\n",
        "download_file(\"d_lstm_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MS9voi2dhBfv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "d_lstm_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uUuDQNShYVv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "d_lstm_oof_prediction = pd.DataFrame()\n",
        "d_lstm_oof_prediction = d_lstm_oof_prediction.reindex(columns = [\"id\"] + category)\n",
        "d_lstm_oof_prediction[\"id\"]= train[[\"id\"]]\n",
        "d_lstm_oof_prediction[category[0:6]] = pd.DataFrame(d_lstm_oof_pred)\n",
        "d_lstm_oof_prediction.to_csv(\"d_lstm_oof_prediction.csv\", index = False)\n",
        "download_file(\"d_lstm_oof_prediction.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olCQdZFVVMyX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import ks_2samp\n",
        "\n",
        "def corr(first_file, second_file):\n",
        "    first_df = first_file\n",
        "    second_df = second_file\n",
        "\n",
        "    for cat in category:\n",
        "        # all correlations\n",
        "        print(\"\\n Class: %s\" % cat)\n",
        "        print(\" Pearson\\'s correlation score: %0.6f\" %\n",
        "              first_df[cat].corr(\n",
        "                  second_df[cat], method = \"pearson\"))\n",
        "        print(\" Kendall\\'s correlation score: %0.6f\" %\n",
        "              first_df[cat].corr(\n",
        "                  second_df[cat], method = \"kendall\"))\n",
        "        print(\" Spearman\\'s correlation score: %0.6f\" %\n",
        "              first_df[cat].corr(\n",
        "                  second_df[cat], method = \"spearman\"))\n",
        "        ks_stat, p_value = ks_2samp(first_df[cat].values,\n",
        "                                    second_df[cat].values)\n",
        "        print(\" Kolmogorov-Smirnov test:    KS-stat = %.6f    p-value = %.6e\\n\"\n",
        "              % (ks_stat, p_value))\n",
        "corr(lstm_submission, gru_submission)\n",
        "corr(lstm_submission, dpcnn_submission)\n",
        "corr(gru_submission, dpcnn_submission)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lechzonx9o74",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}