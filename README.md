# Kaggle

Most challenges were done in Kaggle kernel, except Toxic Comment Challenge. 

**Note**
* In the Quora Insincere Questions Classification Challenge, our solution was able to rank in top 6% before LB median increased to 0.70.


**Helpful Kernels**
* [Download csv files: from kernels](https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel)
* [Good kernels summary](https://www.kaggle.com/shivamb/data-science-glossary-on-kaggle)
* [Visualization of time series](https://www.kaggle.com/thebrownviking20/everything-you-can-do-with-a-time-series?)
* [Noise and Overfitting](https://www.kaggle.com/konstantinmasich/theory-noise-and-overfitting)


**BOOKS**
* [Deep Learning](https://www.deeplearningbook.org/)
* [Pattern Recognition and Machine Learning](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20%20Pattern%20Recognition%20And%20Machine%20Learning%20%20Springer%20%202006.pd)
* [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)
* [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)
* [Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning](https://arxiv.org/pdf/1811.12808.pdf)
