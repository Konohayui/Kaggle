{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "929362b8-f8bd-4bbc-9e2d-68d6c5641742",
        "_uuid": "de9d54e153edc44f6dedc4a2a703c2a7c1512f2e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport random\nimport sys\nimport warnings\nimport numpy as np\n# Setting seed for reproducability\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed\nsmooth = 1.\n\nimport pandas as pd\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom keras.utils import Progbar\nimport cv2\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose,Convolution2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport tensorflow as tf\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8ad211b9-fc60-4482-bb8f-98ae7556adc6",
        "collapsed": true,
        "_uuid": "0bb9294f1bef33e3f84de09ebd7339deef6bbfff",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Data Path\nTRAIN_PATH = '../input/stage1_train/'\nTEST_PATH = '../input/stage2_test_final/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9f2da2db-e0ba-451b-b8f9-f8dd5215ef2e",
        "collapsed": true,
        "_uuid": "f1b0bbf30e053f00f0e393bcb2f6180120501b7b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Get train and test IDs\ntrain_ids = next(os.walk(TRAIN_PATH))[1]\ntest_ids = next(os.walk(TEST_PATH))[1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0d9f57ee-2c5f-464c-b11c-6d9fb82c2d36",
        "collapsed": true,
        "_uuid": "bcca17a77af3e6ac4e821c0a39f46117ce1acf2c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Function read train images and mask return as nump array\ndef read_train_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    print('Getting and resizing train images and masks ... ')\n    sys.stdout.flush()\n    if os.path.isfile(\"train_img.npy\") and os.path.isfile(\"train_mask.npy\"):\n        print(\"Train file loaded from memory\")\n        X_train = np.load(\"train_img.npy\")\n        Y_train = np.load(\"train_mask.npy\")\n        return X_train,Y_train\n    a = Progbar(len(train_ids))\n    for n, id_ in enumerate(train_ids):\n        path = TRAIN_PATH + id_\n        img = cv2.imread(os.path.join(path + '/images/' , id_ + '.png'))[:,:,:IMG_CHANNELS]\n#         img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        X_train[n] = img\n        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n        for mask_file in next(os.walk(path + '/masks/'))[2]:\n            mask_ = imread(path + '/masks/' + mask_file)\n            mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n                                        preserve_range=True), axis=-1)\n            mask = np.maximum(mask, mask_)\n        Y_train[n] = mask\n        a.update(n)\n    np.save(\"train_img\",X_train)\n    np.save(\"train_mask\",Y_train)\n    return X_train,Y_train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1020576e-3508-4533-b650-6a7cb0f01570",
        "collapsed": true,
        "_uuid": "b71ad5f17a08f83c3a2daa5b346f0a1398dd7864",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Function to read test images and return as numpy array\ndef read_test_data(IMG_WIDTH=256,IMG_HEIGHT=256,IMG_CHANNELS=3):\n    X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n    sizes_test = []\n    print('\\nGetting and resizing test images ... ')\n    sys.stdout.flush()\n    if os.path.isfile(\"test_img.npy\") and os.path.isfile(\"test_size.npy\"):\n        print(\"Test file loaded from memory\")\n        X_test = np.load(\"test_img.npy\")\n        sizes_test = np.load(\"test_size.npy\")\n        return X_test,sizes_test\n    b = Progbar(len(test_ids))\n    for n, id_ in enumerate(test_ids):\n        path = TEST_PATH + id_\n        img = cv2.imread(os.path.join(path + '/images/' , id_ + '.png'))[:,:,:IMG_CHANNELS]\n#         try:\n#             img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n#         except:\n#             img = imread(path + '/images/' + id_ + '.png')[:,:IMG_CHANNELS-1]\n        sizes_test.append([img.shape[0], img.shape[1]])\n        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n        X_test[n] = img\n        b.update(n)\n    np.save(\"test_img\",X_test)\n    np.save(\"test_size\",sizes_test)\n    return X_test,sizes_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e36a8f15-1aa0-4e14-94ac-7ba3947d66b0",
        "collapsed": true,
        "_uuid": "3cf1c0b7cb81f7eac5e24d49464fad57d53382a8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ce072a1f-0005-4be2-afde-daf9cb75382b",
        "collapsed": true,
        "_uuid": "2ffedf8ec878eb7c071825e123f85258c36a65aa",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage\ndef mask_to_rle(preds_test_upsampled):\n    new_test_ids = []\n    rles = []\n    for n, id_ in enumerate(test_ids):\n        rle = list(prob_to_rles(preds_test_upsampled[n]))\n        rles.extend(rle)\n        new_test_ids.extend([id_] * len(rle))\n    return new_test_ids,rles",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f7a52daa-4cc7-4f6c-a10d-38e623738b11",
        "collapsed": true,
        "_uuid": "a27a41c086b7b210298d51997cec474dccaeb552",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Metric function\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Loss funtion\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n  \ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "45625625-5e4a-41b8-a7ce-62f783513873",
        "collapsed": true,
        "_uuid": "a7715a922ecb4576dbe0503b919ac5a8f62d0375",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def get_unet(lr, de, IMG_WIDTH=256, IMG_HEIGHT=256, IMG_CHANNELS=3):\n    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n    s = Lambda(lambda x: x / 255) (inputs)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer=Adam(lr=lr, decay=de),loss='binary_crossentropy', metrics=[mean_iou])\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fa5843b4-8630-41a9-9ca1-b9fc7540d75a",
        "_uuid": "e7c5c5e9bb7cf01e2ec4a9a9491ee67961fc82cf",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# get train_data\ntrain_img,train_mask = read_train_data()\n\n# get test_data\ntest_img,test_img_sizes = read_test_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dd8a0316-f9de-4736-b55a-e859e9738ae2",
        "collapsed": true,
        "_uuid": "a4d9fdd5593f1818710722ce89ced2c52d46eadc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "file_path = \"model.hdf5\"\ncheck_point = ModelCheckpoint(file_path, verbose = 1, save_best_only = True)\nearly_stop = EarlyStopping(patience = 5, verbose = 1)\ndatagen = ImageDataGenerator(featurewise_center = False, # set input mean to 0 over the dataset\n                             samplewise_center = False, # set each sample mean to 0\n                             featurewise_std_normalization = False,  # divide inputs by std of the dataset\n                             samplewise_std_normalization = False,  # divide each input by its std\n                             zca_whitening = False,  # apply ZCA whitening\n                             rotation_range = 0,  # randomly rotate images in the range (degrees, 0 to 180)\n                             zoom_range = 0, # Randomly zoom image \n                             width_shift_range = 0, # randomly shift images horizontally (fraction of total width)\n                             height_shift_range = 0, # randomly shift images vertically (fraction of total height)\n                             horizontal_flip = True, # randomly flip images\n                             vertical_flip = False) # randomly flip images\n\ndatagen.fit(train_img)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "720d5a90-67ca-48de-b251-2d565e205970",
        "scrolled": false,
        "_uuid": "1ce20c9848d8c6c2835035cb0ffaf89a00c93069",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# fit model on train_data\nprint(\"\\nTraining...\")\nmodel = get_unet(lr = 1e-4, de = 1e-5)\nepochs = 50\nbatch_size = 16\nnrow_train = len(train_img)\n\nvalid = True\nif valid:\n    model.fit_generator(datagen.flow(train_img, train_mask,\n                                     batch_size = batch_size), epochs = 20, \n                        validation_data = (train_img[int(nrow_train*0.9):,], train_mask[int(nrow_train*0.9):,]),\n                        steps_per_epoch = nrow_train/batch_size,\n                        callbacks = [check_point, early_stop])\n#     history = model.fit(train_img, train_mask, validation_split=0.1, batch_size=batch_size, epochs=epochs, \n#                         callbacks=[check_point, early_stop])\nelse:\n    model.fit_generator(datagen.flow(train_img, train_mask,\n                                     batch_size = batch_size), epochs = 15, \n                        steps_per_epoch = nrow_train/batch_size,\n                        callbacks = [check_point, early_stop])\n#     history = model.fit(train_img, train_mask, batch_size=batch_size, epochs=epochs, \n#                         callbacks=[check_point, early_stop])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "95237530-502d-4075-a683-53b7e01828e3",
        "collapsed": true,
        "_uuid": "01d102a812e85e86bb03567c50ce1c8cbca805de",
        "trusted": false
      },
      "cell_type": "code",
      "source": "model = load_model(file_path, custom_objects={'mean_iou': mean_iou})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6dfd73e1-b361-49a0-b5da-ab06b3e50dd0",
        "collapsed": true,
        "_uuid": "5c2dd086652bdcd354a95d87684cbdac18ea3a2f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"Predicting\")\n# Predict on test data\ntest_mask = model.predict(test_img,verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1d6c52c4-fb56-4375-862e-a65103b100b2",
        "collapsed": true,
        "_uuid": "7d730acfde21ad9cf94d0075030004363cb80601",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create list of upsampled test masks\ntest_mask_upsampled = []\nfor i in range(len(test_mask)):\n    test_mask_upsampled.append(resize(np.squeeze(test_mask[i]),\n                                       (test_img_sizes[i][0],test_img_sizes[i][1]), \n                                       mode='constant', preserve_range=True))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2b09cbf4-bc1d-4de3-9a62-22dbc8efbd56",
        "collapsed": true,
        "_uuid": "2a883cdf1280f233f959e651197b6fe6ad426546",
        "trusted": false
      },
      "cell_type": "code",
      "source": "test_ids,rles = mask_to_rle(test_mask_upsampled)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e396e44c-cf8d-473a-b16b-69f4ec61fdb4",
        "collapsed": true,
        "_uuid": "f233e84430dd0f48b3bb845bcda47ffbbbdb70c1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create submission DataFrame\nsubmission = pd.DataFrame()\nsubmission['ImageId'] = test_ids\nsubmission['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n\nsubmission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5a5f2994-016b-4506-8f24-32ad7d55fc6e",
        "collapsed": true,
        "_uuid": "13ae9defe3adfe2a69d9880884e39e2419f10520",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "47e50ee66746edf09d3c8ba18ee0b7e92e5029a7"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}